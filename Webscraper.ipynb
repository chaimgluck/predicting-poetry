{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraper:\n",
    "A general rule of data science is that no data science project can begin without data. This project follows that principle exactly. Unfortunately, I could not find a suitable digital corpus of poetry published with text from different eras. So I got to collect my own. What follows is the code for my webscraper, and some initial data cleaning.\n",
    "\n",
    "I settled on a website that contained many poems from different eras. The challenge with scraping this website was that both the HTML structure and the URL scheme weren't designed very cleanly, so it wasn't just a simple scrape. In order to collect the URL's for each poem, I first scraped the URL's for each poet's landing page, which led to a page containing the links for each poem. I then scraped the links for each poem, ending with a list of about 32,000 URL's. I then scraped each of those URL's to collect the text of the poem embedded in the HTML. The Python package used for manipulating HTML code contains a convenient method for getting all the actual text from HTML, but in this situation, that would have pushed the ends of the lines of each poem together, causing me to lose some words. Instead, I decided to manually clean each poem using Python functions to extract the poem text from the HTML code. This process was more time-consuming, but considering the importance of every word in this stylistic analysis, it was certainly worth the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Imports.\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Url contains list of all poets on site.\n",
    "all_poets_page = requests.get('http://www.famouspoetsandpoems.com/poets.html')\n",
    "all_poets_page = BeautifulSoup(all_poets_page.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting years for each poet\n",
    "In the code below, I scrape the web page that has the years of each poet's life. This was how I was able to separate the poems into eras. It isn't as clean as using the publication date of each poem, but I felt it justified for two reasons:\n",
    "+ Retrieving the publication years of each poem would be a very time-consuming process, assuming that the dates even exist for each poem. \n",
    "+ I made what I believe to be a safe assumption; A poet's style likely follows the style of their era. That said, it is unlikely that they would change their style as the style changes around them. It is more likely that their style stays somewhat consistent throughout their life. Going forward, I intend to find a better way to classify the poets and their works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_poets_and_years(all_poets_page):\n",
    "    poets = list()\n",
    "    for tag in all_poets_page.findAll('td'):\n",
    "        if '(' in tag.get_text():\n",
    "            poets.append(tag.get_text().strip())\n",
    "    poets = [x.strip() for x in poets]\n",
    "    poets = poets[3:]\n",
    "    poets = poets[::2]\n",
    "    return poets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Maya Angelou (18)(1928 - present)',\n",
       " u'Margaret Atwood (28)(1939 - present)',\n",
       " u'Matthew Arnold (45)(1822 - 1888)',\n",
       " u'Yehuda Amichai (38)(1924 - 2000)',\n",
       " u'Anna Akhmatova (26)(1889 - 1966)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poets = grab_poets_and_years(all_poets_page)\n",
    "poets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_poet_info(poet_string):\n",
    "    poet_name = re.findall('^[^\\(]+', poet_string)[0].strip()\n",
    "    number_of_poems = re.findall('\\((.*?)\\)', poet_string)[0]\n",
    "    poet_years = re.findall('\\((.*?)\\)', poet_string)[1]\n",
    "    return poet_name, number_of_poems, poet_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(631, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poets_info = map(extract_poet_info, poets)\n",
    "poets_df = pd.DataFrame(poets_info, columns=['name', 'number', 'years'])\n",
    "poets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poets_df.to_csv('poets_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping a list of links to each poet's page.\n",
    "The website I'm retrieving my poems from required some clever webscraping. First, I had to collect links to each poet's landing page. These pages each contain links to all of that poet's poems. So after I have all the poet pages, I collect all the links for all of their poems. Then I scrape the actual poem from each of those pages. It amounted to over 32,000 pages that I scraped in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_poet_links(all_poets_page):\n",
    "    poet_links = list()\n",
    "    for tag in all_poets_page.findAll('td'):\n",
    "        try:\n",
    "            link = tag.find('a')['href']\n",
    "            if '/poets/' in link:\n",
    "                poet_links.append(link)\n",
    "        except:\n",
    "            pass\n",
    "    poet_links = list(set(poet_links))\n",
    "    base = 'http://www.famouspoetsandpoems.com'\n",
    "    poet_pages = [base + poet + '/poems' for poet in poet_links]\n",
    "    return poet_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.famouspoetsandpoems.com/poets/rebecca_elson/poems',\n",
       " 'http://www.famouspoetsandpoems.com/poets/james_thomson/poems',\n",
       " 'http://www.famouspoetsandpoems.com/poets/anne_kingsmill_finch/poems',\n",
       " 'http://www.famouspoetsandpoems.com/poets/julia_ward_howe/poems',\n",
       " 'http://www.famouspoetsandpoems.com/poets/conrad_aiken/poems']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_poet_pages = extract_poet_links(all_poets_page)\n",
    "all_poet_pages[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function collects all the links for individual poems from each poet's landing page.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_poems(poet_page):\n",
    "    poet_page = requests.get(poet_page)\n",
    "    bib_soup = BeautifulSoup(poet_page.text, 'lxml')\n",
    "    \n",
    "    raw_poem_links = list()\n",
    "    for poems in bib_soup.findAll('td'):\n",
    "        try:\n",
    "            poem = poems.find('a')['href']\n",
    "            if '/poems/' in poem:\n",
    "                raw_poem_links.append(poem)\n",
    "        except:\n",
    "            pass     \n",
    "    raw_poem_links = list(set(raw_poem_links))\n",
    "    poem_links = ['http://www.famouspoetsandpoems.com' + poem for poem in raw_poem_links]\n",
    "    return poem_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41807373365\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "all_poem_links = map(get_poems, all_poet_pages)\n",
    "print((time() - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.famouspoetsandpoems.com/poets/rebecca_elson/poems/22156',\n",
       " 'http://www.famouspoetsandpoems.com/poets/rebecca_elson/poems/22157',\n",
       " 'http://www.famouspoetsandpoems.com/poets/james_thomson/poems/4078',\n",
       " 'http://www.famouspoetsandpoems.com/poets/james_thomson/poems/4088',\n",
       " 'http://www.famouspoetsandpoems.com/poets/james_thomson/poems/4080']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_poem_links_list = [item for sublist in all_poem_links for item in sublist]\n",
    "all_poem_links_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping all the poems from site:\n",
    "Below, I go to each link in the list of 32,000 pages and scrape the actual poem from the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d689366389f24729841063ea42304be5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time()\n",
    "poems_soup = []\n",
    "for link in tqdm(all_poem_links_list, desc='Scrape all poems'):\n",
    "    url = requests.get(link)\n",
    "    soup = BeautifulSoup(url.text, 'lxml')\n",
    "    poem = soup.find('div', style=\"padding-left:14px;padding-top:20px;font-family:Arial;font-size:13px;\")\n",
    "    for tag in soup('span'):\n",
    "        if 'by' in tag.get_text():\n",
    "            poet = tag.get_text().strip()\n",
    "    poems_soup.append([poem, poet])\n",
    "print((time() - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If scrape was interrupted, continue from where you left off.\n",
    "start = time()\n",
    "poems_soup = []\n",
    "for link in tqdm(all_poem_links_list[len(poems_soup):], len(all_poem_links_list)):\n",
    "    url = requests.get(link)\n",
    "    soup = BeautifulSoup(url.text, 'lxml')\n",
    "    poem = soup.find('div', style=\"padding-left:14px;padding-top:20px;font-family:Arial;font-size:13px;\")\n",
    "    for tag in soup('span'):\n",
    "        if 'by' in tag.get_text():\n",
    "            poet = tag.get_text().strip()\n",
    "    poems_soup.append([poem, poet])\n",
    "print((time() - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating a DataFrame from all the poems and poets.\n",
    "df_all = pd.DataFrame(poems_soup)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.to_csv('all_poets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Just a peek at what we're dealing with. It will need cleaning.\n",
    "for i in df_all[0][0:5]:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(poems_soup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
